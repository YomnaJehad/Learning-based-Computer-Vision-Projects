{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34682b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessariy libraries\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75fb04b",
   "metadata": {},
   "source": [
    "## 1.2 Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0213331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader ():\n",
    "    # define the required paths\n",
    "    base_path = 'textures/'\n",
    "    train_test_path = ['training/' ,'testing/']\n",
    "    folders_names = ['canvas1/', 'cushion1/', 'linsseeds1/', 'sand1/', 'seat2/', 'stone1/']\n",
    "\n",
    "    train_canvas1, train_cushion1, train_linsseeds1, train_sand1, train_seat2, train_stone1 = [], [], [], [], [], []\n",
    "    test_canvas1, test_cushion1, test_linsseeds1, test_sand1, test_seat2, test_stone1 = [], [], [], [], [], []\n",
    "    images_list = [[train_canvas1, train_cushion1, train_linsseeds1, train_sand1, train_seat2, train_stone1],\n",
    "                   [test_canvas1, test_cushion1, test_linsseeds1, test_sand1, test_seat2, test_stone1]]\n",
    "    for i in range (0,2):\n",
    "\n",
    "        # extract a list of file names in each directory\n",
    "        folders_list = os.listdir( base_path+train_test_path[i] )\n",
    "        print('Numebr of folders in',train_test_path[i],': ' ,len(folders_list))\n",
    "\n",
    "        for j, item in enumerate(folders_list):\n",
    "            files_list = os.listdir( base_path+train_test_path[i]+item+'/' )\n",
    "            for k,file in enumerate(files_list):\n",
    "                image = imread(base_path+train_test_path[i]+item+'/'+file)\n",
    "\n",
    "                resized = resize(image, (32, 32), preserve_range=True) \n",
    "                gray = rgb2gray(resized)\n",
    "                images_list[i][j].append(np.array(gray))\n",
    "    #             pyplot.imshow(image)\n",
    "    #             pyplot.show()\n",
    "            images_list[i][j] = np.array(images_list[i][j])\n",
    "        images_list[i] = np.array(images_list[i])\n",
    "\n",
    "    train_canvas1, train_cushion1, train_linsseeds1, train_sand1, train_seat2, train_stone1 = images_list[0][0], images_list[0][1], images_list[0][2], images_list[0][3], images_list[0][4], images_list[0][5]\n",
    "    test_canvas1, test_cushion1, test_linsseeds1, test_sand1, test_seat2, test_stone1 = images_list[1][0], images_list[1][1], images_list[1][2], images_list[1][3], images_list[1][4], images_list[1][5]\n",
    "    # Create train set\n",
    "    X_train = np.concatenate([train_canvas1, train_cushion1, train_linsseeds1, train_sand1, train_seat2, train_stone1])\n",
    "    # Create label for train set\n",
    "    y_train = np.zeros (X_train.shape[0])\n",
    "    y_train[0:train_canvas1.shape[0]] = 0\n",
    "    y_train[train_canvas1.shape[0]:train_canvas1.shape[0]+train_cushion1.shape[0]] = 1\n",
    "    y_train[train_canvas1.shape[0]+train_cushion1.shape[0]:train_canvas1.shape[0]+train_cushion1.shape[0]+train_linsseeds1.shape[0]] = 2\n",
    "    y_train[train_canvas1.shape[0]+train_cushion1.shape[0]+train_linsseeds1.shape[0]:train_canvas1.shape[0]+train_cushion1.shape[0]+train_linsseeds1.shape[0]+train_sand1.shape[0]] = 3\n",
    "    y_train[train_canvas1.shape[0]+train_cushion1.shape[0]+train_linsseeds1.shape[0]+train_sand1.shape[0]:train_canvas1.shape[0]+train_cushion1.shape[0]+train_linsseeds1.shape[0]+train_sand1.shape[0]+train_seat2.shape[0]] = 4\n",
    "    y_train[train_canvas1.shape[0]+train_cushion1.shape[0]+train_linsseeds1.shape[0]+train_sand1.shape[0]+train_seat2.shape[0]:train_canvas1.shape[0]+train_cushion1.shape[0]+train_linsseeds1.shape[0]+train_sand1.shape[0]+train_seat2.shape[0]+train_stone1.shape[0]] = 5\n",
    "    \n",
    "    \n",
    "    # Creat test set\n",
    "    X_test = np.concatenate([test_canvas1, test_cushion1, test_linsseeds1, test_sand1, test_seat2, test_stone1])\n",
    "    # Create label for test set\n",
    "    y_test = np.zeros (X_test.shape[0])\n",
    "    y_test[0:test_canvas1.shape[0]] = 0\n",
    "    y_test[test_canvas1.shape[0]:test_canvas1.shape[0]+test_cushion1.shape[0]] = 1\n",
    "    y_test[test_canvas1.shape[0]+test_cushion1.shape[0]:test_canvas1.shape[0]+test_cushion1.shape[0]+test_linsseeds1.shape[0]] = 2\n",
    "    y_test[test_canvas1.shape[0]+test_cushion1.shape[0]+test_linsseeds1.shape[0]:test_canvas1.shape[0]+test_cushion1.shape[0]+test_linsseeds1.shape[0]+test_sand1.shape[0]] = 3\n",
    "    y_test[test_canvas1.shape[0]+test_cushion1.shape[0]+test_linsseeds1.shape[0]+test_sand1.shape[0]:test_canvas1.shape[0]+test_cushion1.shape[0]+test_linsseeds1.shape[0]+test_sand1.shape[0]+test_seat2.shape[0]] = 4\n",
    "    y_test[test_canvas1.shape[0]+test_cushion1.shape[0]+test_linsseeds1.shape[0]+test_sand1.shape[0]+test_seat2.shape[0]:test_canvas1.shape[0]+test_cushion1.shape[0]+test_linsseeds1.shape[0]+test_sand1.shape[0]+test_seat2.shape[0]+test_stone1.shape[0]] = 5\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2de1b3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numebr of folders in training/ :  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-70e6c94766ad>:23: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\n",
      "  gray = rgb2gray(resized)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numebr of folders in testing/ :  6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((180, 32, 32), (60, 32, 32), (180,), (60,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = data_loader()\n",
    "X_train.shape , X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b02923",
   "metadata": {},
   "source": [
    "## 1.3 Image Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd55b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ( imageA, imageB, method=cc|conv|ssd, normalize=y|n)\n",
    "def matchingImages (a, b, method=\"cc\", normalize='n'):\n",
    "    \n",
    "    result, np_result = 0, 0\n",
    "    # define thresholds\n",
    "    cc_threshold = 16260381 # 16250606\n",
    "    conv_threshold = 16251165 # 16240502\n",
    "    ssd_threshold = 475521 # 222979\n",
    "    # initializations\n",
    "    match = 0\n",
    "    std = 1\n",
    "    a_zero_mean = a.copy()\n",
    "    b_zero_mean = b.copy()\n",
    "    \n",
    "    if normalize == 'y':\n",
    "        std = (np.sum((b-np.mean(b))**2) * np.sum((a-np.mean(a))**2))** 0.5\n",
    "        a_zero_mean = a - np.mean(a)\n",
    "        b_zero_mean = b - np.mean(b)\n",
    "        cc_threshold = 0.051464586812097785 # 0.042635353182592345\n",
    "        conv_threshold = -3536 # -0.064 \n",
    "        ssd_threshold = 1.9 # 1.93 \n",
    "    \n",
    "    a_zero_mean = a_zero_mean.flatten()\n",
    "    b_zero_mean = b_zero_mean.flatten()\n",
    "    a = a.flatten()\n",
    "    b = b.flatten()\n",
    "    \n",
    "    if method == \"cc\":\n",
    "        sum = 0\n",
    "        for element_a, element_b in zip(a_zero_mean, b_zero_mean):\n",
    "            sum = sum + element_a * element_b\n",
    "        result = sum\n",
    "        result = result / std\n",
    "        # np_result = np.correlate(a_zero_mean,b_zero_mean)\n",
    "        \n",
    "        \n",
    "        if result >= cc_threshold:\n",
    "            match = 1\n",
    "            \n",
    "    \n",
    "    if method == \"conv\":\n",
    "        b_flipped = np.flip(b)\n",
    "        sum = 0\n",
    "        for element_a, element_b in zip(a_zero_mean, b_flipped):\n",
    "            sum = sum + element_a * element_b\n",
    "        result = sum\n",
    "        # result = result / std\n",
    "        # np_result= np.convolve(a_zero_mean,b)\n",
    "        \n",
    "        if result >= conv_threshold:\n",
    "            match = 1\n",
    "        \n",
    "    if method == \"ssd\":\n",
    "        sum = 0\n",
    "        for element_a, element_b in zip(a_zero_mean, b_zero_mean):\n",
    "            sum = sum + ((element_a - element_b)) ** 2\n",
    "        result = sum\n",
    "        result = result / std\n",
    "        # np_result = np.sum((a - b)**2)\n",
    "        \n",
    "        if result <= ssd_threshold:\n",
    "            match = 1\n",
    "    return result, np_result, match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1625c1c",
   "metadata": {},
   "source": [
    "### Get the average of CC, Conv, SSD to be able to set the thresholds properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4822608a",
   "metadata": {},
   "source": [
    "### No normalization CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b500dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16251497.379310345\n",
      "16258055.603448275\n",
      "16264102.323275862\n",
      "16260259.36637931\n",
      "16265953.534482758\n",
      "16262420.85775862\n",
      "___________\n",
      "Avergae:  16260381.510775864\n",
      "Cross Correlation result: 16252144.25   || match:  0\n",
      "Cross Correlation result: 16239722.8125   || match:  0\n",
      "Cross Correlation result: 16238906.9375   || match:  0\n"
     ]
    }
   ],
   "source": [
    "big_sum = 0\n",
    "i, j = 0, 0\n",
    "# iter = 0\n",
    "for i in [0,30,60,90,120,150]:\n",
    "    sum = 0\n",
    "    for j in range(i, i+29):\n",
    "        result, _, match = matchingImages(X_train[j],X_train[j+1])\n",
    "        sum += result\n",
    "        # iter +=1\n",
    "    print(sum/29)\n",
    "    big_sum += sum/29\n",
    "#print(iter)\n",
    "print(\"___________\")\n",
    "print(\"Avergae: \" ,big_sum/6)\n",
    "\n",
    "# TEST\n",
    "\n",
    "result, _, match = matchingImages(X_train[1],X_train[8])\n",
    "print(\"Cross Correlation result:\",result,\"  || match: \", match)\n",
    "result, _, match = matchingImages(X_train[1],X_train[100])\n",
    "print(\"Cross Correlation result:\",result,\"  || match: \", match)\n",
    "result, _, match = matchingImages(X_train[1],X_train[70])\n",
    "print(\"Cross Correlation result:\",result,\"  || match: \", match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab8aa9",
   "metadata": {},
   "source": [
    "### No normalization Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c37a8392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16237012.978448275\n",
      "16247005.898706896\n",
      "16259012.76724138\n",
      "16254975.484913792\n",
      "16255743.459051725\n",
      "16253244.217672413\n",
      "___________\n",
      "Avergae:  16251165.801005745\n",
      "Convolution result: 16241995.8125   || match:  0\n",
      "Convolution result: 16254816.75   || match:  1\n",
      "Convolution result: 16250798.5625   || match:  0\n"
     ]
    }
   ],
   "source": [
    "big_sum = 0\n",
    "i, j = 0, 0\n",
    "for i in [0,30,60,90,120,150]:\n",
    "    sum = 0\n",
    "    for j in range(i, i+29):\n",
    "        result, _, match = matchingImages(X_train[j],X_train[j+1], method = \"conv\")\n",
    "        sum += result\n",
    "    print(sum/29)\n",
    "    big_sum += sum/29\n",
    "print(\"___________\")\n",
    "print(\"Avergae: \", big_sum/6)\n",
    "\n",
    "# TEST\n",
    "\n",
    "result, _, match = matchingImages(X_train[1],X_train[150] , method = \"conv\")\n",
    "print(\"Convolution result:\",result,  \"  || match: \", match)\n",
    "result, _, match = matchingImages(X_train[119],X_train[120] , method = \"conv\")\n",
    "print(\"Convolution result:\",result, \"  || match: \", match)\n",
    "result, _, match = matchingImages(X_train[1],X_train[50] , method = \"conv\")\n",
    "print(\"Convolution result:\",result, \"  || match: \", match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db610d3d",
   "metadata": {},
   "source": [
    "### No normalization SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae2076d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197076.68318965516\n",
      "547059.504310345\n",
      "839294.1422413794\n",
      "487560.7521551724\n",
      "78891.0086206896\n",
      "703244.0969827586\n",
      "___________\n",
      "Avergae:  475521.03125\n",
      "Sum of square differences result: 175151.0625   || match:  1\n",
      "Sum of square differences result: 548936.75   || match:  0\n",
      "Sum of square differences result: 684113.9999999999   || match:  0\n"
     ]
    }
   ],
   "source": [
    "big_sum = 0\n",
    "i, j = 0, 0\n",
    "for i in [0,30,60,90,120,150]:\n",
    "    sum = 0\n",
    "    for j in range(i, i+29):\n",
    "        result, _, match = matchingImages(X_train[j],X_train[j+1], method = \"ssd\")\n",
    "        sum += result\n",
    "    print(sum/29)\n",
    "    big_sum += sum/29\n",
    "print(\"___________\")\n",
    "print(\"Avergae: \" , big_sum/6)\n",
    "\n",
    "# TEST\n",
    "\n",
    "result, _, match = matchingImages(X_train[1],X_train[15] , method = \"ssd\")\n",
    "print(\"Sum of square differences result:\",result, \"  || match: \", match)\n",
    "result, _, match = matchingImages(X_train[179],X_train[100] , method = \"ssd\")\n",
    "print(\"Sum of square differences result:\",result,\"  || match: \", match)\n",
    "result, _, match = matchingImages(X_train[30],X_train[150] , method = \"ssd\")\n",
    "print(\"Sum of square differences result:\",result, \"  || match: \", match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92823fe",
   "metadata": {},
   "source": [
    "### Normalized CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8e15326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05786909942394834\n",
      "0.0019503285986316923\n",
      "0.016636571575031508\n",
      "0.010289518398571474\n",
      "0.20585243593270655\n",
      "0.016189566943697175\n",
      "___________\n",
      "Avergae:  0.051464586812097785\n",
      "Normalized Cross Correlation result: 0.0772027002787194   || match:  1\n",
      "Normalized Cross Correlation result: -0.0954746683498355   || match:  0\n",
      "Normalized Cross Correlation result: -0.04444502948682246   || match:  0\n"
     ]
    }
   ],
   "source": [
    "big_sum = 0\n",
    "i, j = 0, 0\n",
    "for i in [0,30,60,90,120,150]:\n",
    "    sum = 0\n",
    "    for j in range(i, i+29):\n",
    "        result, _, match = matchingImages(X_train[j],X_train[j+1], method = \"cc\", normalize = 'y')\n",
    "        sum += result\n",
    "    print(sum/29)\n",
    "    big_sum += sum/29\n",
    "print(\"___________\")\n",
    "print(\"Avergae: \", big_sum/6)\n",
    "\n",
    "# TEST\n",
    "\n",
    "result, _, match = matchingImages(X_train[1],X_train[7] , normalize = 'y')\n",
    "print(\"Normalized Cross Correlation result:\",result, \"  || match: \", match)\n",
    "result, _, match = matchingImages(X_train[1],X_train[120] , normalize = 'y')\n",
    "print(\"Normalized Cross Correlation result:\",result, \"  || match: \", match)\n",
    "result, _, match = matchingImages(X_train[1],X_train[70] , normalize = 'y')\n",
    "print(\"Normalized Cross Correlation result:\",result, \"  || match: \", match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6d6f9",
   "metadata": {},
   "source": [
    "### Normalized Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6b751b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7816.1331871295\n",
      "-10022.302492338973\n",
      "2366.166840651933\n",
      "-2573.0706850249558\n",
      "46.709718901444454\n",
      "-3222.5800718109235\n",
      "___________\n",
      "Avergae:  -3536.868312791829\n",
      "Normalized Convolution result: 23274.510742187864   || match:  1\n",
      "Normalized Convolution result: -14092.34649658195   || match:  0\n",
      "Normalized Convolution result: -7782.621398925584   || match:  0\n"
     ]
    }
   ],
   "source": [
    "big_sum = 0\n",
    "i, j = 0, 0\n",
    "for i in [0,30,60,90,120,150]:\n",
    "    sum = 0\n",
    "    for j in range(i, i+29):\n",
    "        result, _, match = matchingImages(X_train[j],X_train[j+1], method = \"conv\", normalize = 'y')\n",
    "        sum += result\n",
    "    print(sum/29)\n",
    "    big_sum += sum/29\n",
    "print(\"___________\")\n",
    "print(\"Avergae: \", big_sum/6)\n",
    "\n",
    "# TEST\n",
    "\n",
    "result, _, match = matchingImages(X_train[179],X_train[155] , method = \"conv\", normalize = 'y')\n",
    "print(\"Normalized Convolution result:\",result,\"  || match: \", match)\n",
    "result, _, match = matchingImages(X_train[1],X_train[2] , method = \"conv\", normalize = 'y')\n",
    "print(\"Normalized Convolution result:\",result,\"  || match: \", match)\n",
    "result, _, match = matchingImages(X_train[1],X_train[150] , method = \"conv\", normalize = 'y')\n",
    "print(\"Normalized Convolution result:\",result,\"  || match: \", match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18deafca",
   "metadata": {},
   "source": [
    "### Normalized SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e8830b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8924298839827622\n",
      "2.0000764517046914\n",
      "1.9681731166518655\n",
      "1.984934889317656\n",
      "1.5908062206131424\n",
      "1.9692285643837524\n",
      "___________\n",
      "Avergae:  1.9009415211089784\n",
      "Normalized Sum of square differences result: 1.688754246324758   || match: 1\n",
      "Normalized Sum of square differences result: 2.2410422985098233   || match: 0\n",
      "Normalized Sum of square differences result: 2.1697392859568807   || match: 0\n"
     ]
    }
   ],
   "source": [
    "big_sum = 0\n",
    "i, j = 0, 0\n",
    "for i in [0,30,60,90,120,150]:\n",
    "    sum = 0\n",
    "    for j in range(i, i+29):\n",
    "        result, _, match = matchingImages(X_train[j],X_train[j+1], method = \"ssd\", normalize = 'y')\n",
    "        sum += result\n",
    "    print(sum/29)\n",
    "    big_sum += sum/29\n",
    "print(\"___________\")\n",
    "print(\"Avergae: \", big_sum/6)\n",
    "\n",
    "# TEST\n",
    "\n",
    "result, _, match = matchingImages(X_train[1],X_train[15] , method = \"ssd\", normalize = 'y')\n",
    "print(\"Normalized Sum of square differences result:\",result,\"  || match:\", match)\n",
    "result, _, match = matchingImages(X_train[1],X_train[100] , method = \"ssd\", normalize = 'y')\n",
    "print(\"Normalized Sum of square differences result:\",result, \"  || match:\", match)\n",
    "result, _, match = matchingImages(X_train[1],X_train[50] , method = \"ssd\", normalize = 'y')\n",
    "print(\"Normalized Sum of square differences result:\",result,\"  || match:\", match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146d4e0",
   "metadata": {},
   "source": [
    "## Preparing Train and Validation Set\n",
    "#### take 10 images of each category for validation and the rest 20 for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c61ac018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 32, 32), (60,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = []\n",
    "y_val = []\n",
    "i, j = 0, 0\n",
    "for i in [0,30,60,90,120,150]:\n",
    "    for j in range(i, i+10):\n",
    "        X_val.append(X_train[j])\n",
    "        y_val.append(y_train[j])\n",
    "        \n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0962cdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27cd49a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 32, 32) (120,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "# new train set\n",
    "X_train_reduced = []\n",
    "y_train_reduced = []\n",
    "i, j = 0, 0\n",
    "for i in [0,30,60,90,120,150]:\n",
    "    for j in range(i+10,i+30):\n",
    "        X_train_reduced.append(X_train[j])\n",
    "        y_train_reduced.append(y_train[j])\n",
    "X_train_reduced = np.array(X_train_reduced)\n",
    "y_train_reduced = np.array(y_train_reduced)\n",
    "print(X_train_reduced.shape, y_train_reduced.shape)\n",
    "print(y_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4352e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 1024), (60, 1024))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape these sets\n",
    "X_train_reduced_flattened = X_train_reduced.reshape(X_train_reduced.shape[0], -1)\n",
    "X_val_flattened = X_val.reshape(X_val.shape[0], -1)\n",
    "X_train_reduced_flattened.shape , X_val_flattened.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28bc845",
   "metadata": {},
   "source": [
    "## Matching validation using validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5def6ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_matching_classifier(X, y, method = \"cc\", normalize = 'n'):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    positive_wins = 0\n",
    "    negative_wins = 0\n",
    "    positive_fails = 0\n",
    "    negative_fails = 0\n",
    "    no_iter = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range (i+1,X.shape[0]):\n",
    "            no_iter += 1\n",
    "            result, np_result, match = matchingImages(X[i],X[j], method = method, normalize=normalize)\n",
    "            # all the matching should be 1 except for 6 or 7 iterations\n",
    "            if y[i] == y[j] :\n",
    "                positive_wins += match\n",
    "                positive_fails += (not match)\n",
    "                    \n",
    "            elif y[i] != y[j]:\n",
    "                negative_wins += (not match)\n",
    "                negative_fails += match\n",
    "                \n",
    "                \n",
    "        \n",
    "    print('TP: ', positive_wins)\n",
    "    print('TN: ', negative_wins)\n",
    "    print('FP: ', negative_fails)\n",
    "    print('FN: ', positive_fails)\n",
    "    print('Number of tests: ', no_iter)\n",
    "    print(\"__________\")\n",
    "    \n",
    "    return positive_wins, negative_wins, positive_fails, negative_fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ea8dfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  132\n",
      "TN:  944\n",
      "FP:  556\n",
      "FN:  138\n",
      "Number of tests:  1770\n",
      "__________\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = validate_matching_classifier(X_val_flattened, y_val, method = \"cc\", normalize = 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1cdc3397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.607909604519774 \n",
      "Recall:  0.19186046511627908 \n",
      "Precesion:  0.4888888888888889 \n",
      "F1 Score:  0.2755741127348643\n"
     ]
    }
   ],
   "source": [
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Recall = TP / (TP + FN)\n",
    "Precision =  TP / (TP + FP)\n",
    "F1 = (2 * Precision * Recall) / (Precision + Recall)\n",
    "print ( \"Accuracy: \", Accuracy,\n",
    "       \"\\nRecall: \", Recall,\n",
    "       \"\\nPrecesion: \", Precision,\n",
    "       \"\\nF1 Score: \", F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d256b4",
   "metadata": {},
   "source": [
    "## Prepare concatenated dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c74ba",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "55a533f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 32, 32), (120,), (7140, 32, 32, 2), (7140,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced_conc = []\n",
    "y_train_reduced_conc = []\n",
    "i, j, k = 0, 0, 0\n",
    "for i in range(X_train_reduced.shape[0]):\n",
    "    for j in range(i+1, X_train_reduced.shape[0]):\n",
    "        #if i != j:\n",
    "        X_train_reduced_conc.append(np.dstack([X_train_reduced[i], X_train_reduced[j]]))\n",
    "        if y_train_reduced[i] == y_train_reduced [j]:\n",
    "            y_train_reduced_conc.append(1)\n",
    "        else:\n",
    "            y_train_reduced_conc.append(0)\n",
    "X_train_reduced_conc = np.array(X_train_reduced_conc)\n",
    "y_train_reduced_conc = np.array(y_train_reduced_conc)\n",
    "X_train_reduced.shape , y_train_reduced.shape, X_train_reduced_conc.shape , y_train_reduced_conc.shape            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e2c16",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2d7f02bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 32, 32), (60,), (1770, 32, 32, 2), (1770,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_conc = []\n",
    "y_val_conc = []\n",
    "i, j, k = 0, 0, 0\n",
    "for i in range(X_val.shape[0]):\n",
    "    for j in range(i+1, X_val.shape[0]):\n",
    "        #if i != j:\n",
    "        X_val_conc.append(np.dstack([X_val[i], X_val[j]]))\n",
    "        if y_val[i] == y_val[j]:\n",
    "            y_val_conc.append(1)\n",
    "        else:\n",
    "            y_val_conc.append(0)\n",
    "X_val_conc = np.array(X_val_conc)\n",
    "y_val_conc = np.array(y_val_conc)\n",
    "X_val.shape , y_val.shape, X_val_conc.shape , y_val_conc.shape          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ab65afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7140, 2048), (1770, 2048))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten them to use for the MLP\n",
    "X_train_reduced_conc_flattened = X_train_reduced_conc.reshape(X_train_reduced_conc.shape[0], -1)\n",
    "X_val_conc_flattened = X_val_conc.reshape(X_val_conc.shape[0], -1)\n",
    "X_train_reduced_conc_flattened.shape , X_val_conc_flattened.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92590b5b",
   "metadata": {},
   "source": [
    "## Train on MLP and test using Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7658a47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8984593837535014 0.6412429378531074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_base = MLPClassifier(random_state=1, max_iter=300).fit(X_train_reduced_conc_flattened, y_train_reduced_conc)\n",
    "print(clf_base.score(X_train_reduced_conc_flattened, y_train_reduced_conc) ,\n",
    "      clf_base.score(X_val_conc_flattened, y_val_conc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c2bbe989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77      1500\n",
      "           1       0.16      0.31      0.21       270\n",
      "\n",
      "    accuracy                           0.64      1770\n",
      "   macro avg       0.50      0.51      0.49      1770\n",
      "weighted avg       0.74      0.64      0.68      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = clf_base.predict(X_val_conc_flattened)\n",
    "print(classification_report(y_val_conc, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fae95743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 6000],\n",
       "       [   1, 1140]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train_reduced_conc, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b7bcc0",
   "metadata": {},
   "source": [
    "#### We notice the great unbalance in the data, maybe if we fix this the classifier will be better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e3817",
   "metadata": {},
   "source": [
    "## Re-sample Train Set\n",
    "#### (Under sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0242d17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2280, 2048), (2280,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn import under_sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# define the undersampling method\n",
    "undersample = NearMiss(version=1, n_neighbors=3)\n",
    "# transform the dataset\n",
    "X_resampled, y_resampled = undersample.fit_resample(X_train_reduced_conc_flattened, y_train_reduced_conc)\n",
    "X_resampled.shape, y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae52a4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 1140],\n",
       "       [   1, 1140]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_resampled, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dce3c9",
   "metadata": {},
   "source": [
    "### Train our MLP on this new Resampled Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d45510f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7649122807017544 0.5830508474576271\n"
     ]
    }
   ],
   "source": [
    "clf_resampled = MLPClassifier(random_state=1, max_iter=300).fit(X_resampled,y_resampled)\n",
    "print(clf_resampled.score(X_resampled, y_resampled) ,\n",
    "      clf_resampled.score(X_val_conc_flattened, y_val_conc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4eaee765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.62      0.72      1500\n",
      "           1       0.15      0.36      0.21       270\n",
      "\n",
      "    accuracy                           0.58      1770\n",
      "   macro avg       0.50      0.49      0.46      1770\n",
      "weighted avg       0.74      0.58      0.64      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_resampled.predict(X_val_conc_flattened)\n",
    "print(classification_report(y_val_conc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c21473",
   "metadata": {},
   "source": [
    "- The performance either did not change or became worse, this could be due that the undersampling resulted in less features, which resulted in the model capturing less details and patterns. A solution to this could be to try oversampling instead. Anyway for now let's stick with our clf_base model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79067439",
   "metadata": {},
   "source": [
    "## Classification Comparison\n",
    " \n",
    " - As we can see the accuracy of the 1st classifier is almost 60%, F1_score = 27% . While the accuracy of MLP is 64% and one F1 is much higher up to 77% for class0. This is an indication of the generlization ability of MLP model. \n",
    " - Regarding the training effort, of course the MLP takes much longer, however, it's more robust. Because hardcoding one threshold for each matching method in the 1st classifier is brone to error and can be actually useless in a real world example where we can not rely on conditional ifs. \n",
    " - The prediction speed of the 1st classifier is higher, because all it does is go through an if condition, while the MLP goes through the multi layers and all of their accompyning calculations in order to reach a prediction.\n",
    " - In general, unless the application is trivial matching application and unless the speed is not an issue, I'd recommend MLP for its generalization and robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd92e79",
   "metadata": {},
   "source": [
    "## 1.6 Feature Engineering\n",
    "### Apply filters and features extraction on data before resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e31fa58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7140, 32, 32, 2), (7140, 32, 32, 2))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced_conc.shape, X_train_reduced_conc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35962f",
   "metadata": {},
   "source": [
    "### Apply Sobel edge detection to help identify the texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "350a1f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import sobel\n",
    "X_train_reduced_conc_sobeled = []\n",
    "for image in X_train_reduced_conc:\n",
    "    sobeled = sobel(image)\n",
    "    X_train_reduced_conc_sobeled.append(sobeled)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "32b36f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7140, 32, 32, 2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced_conc_sobeled = np.array(X_train_reduced_conc_sobeled)\n",
    "X_train_reduced_conc_sobeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3fb647d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7140, 32, 32, 2), (7140, 2048))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced_conc_sobeled_flattened = X_train_reduced_conc_sobeled.reshape(\n",
    "    X_train_reduced_conc_sobeled.shape[0], -1)\n",
    "X_train_reduced_conc_sobeled.shape, X_train_reduced_conc_sobeled_flattened.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e0c3e7",
   "metadata": {},
   "source": [
    "### Apply PCA to reduce dimensionality to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25f5c7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7140, 32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=32)\n",
    "X_train_reduced_conc_sobeled_flattened_pca = pca.fit_transform(X_train_reduced_conc_sobeled_flattened)\n",
    "X_train_reduced_conc_sobeled_flattened_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f12f1",
   "metadata": {},
   "source": [
    "#### Now apply the same things to the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "82b29ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1770, 32, 32, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_conc_sobeled = []\n",
    "for image in X_val_conc:\n",
    "    sobeled = sobel(image)\n",
    "    X_val_conc_sobeled.append(sobeled)\n",
    "X_val_conc_sobeled = np.array(X_val_conc_sobeled)\n",
    "X_val_conc_sobeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "67f0704d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1770, 32, 32, 2), (1770, 2048))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_conc_sobeled_flattened = X_val_conc_sobeled.reshape(X_val_conc_sobeled.shape[0], -1)\n",
    "X_val_conc_sobeled.shape, X_val_conc_sobeled_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1222314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1770, 32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_conc_sobeled_flattened_pca = pca.transform(X_val_conc_sobeled_flattened)\n",
    "X_val_conc_sobeled_flattened_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8d231f",
   "metadata": {},
   "source": [
    "### Apply same feature engineering on data after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3094575f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2280, 2048), (2280,))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape, y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aef10515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2280, 2048)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_conc_sobeled_resampled = []\n",
    "for image in X_resampled:\n",
    "    sobeled = sobel(image)\n",
    "    X_train_conc_sobeled_resampled.append(sobeled)\n",
    "X_train_conc_sobeled_resampled = np.array(X_train_conc_sobeled_resampled)\n",
    "X_train_conc_sobeled_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1f266490",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_resampled = PCA(n_components=32)\n",
    "X_train_conc_sobeled_resampled_pca = pca_resampled.fit_transform(X_train_conc_sobeled_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5336e24",
   "metadata": {},
   "source": [
    "#### Now only apply the PCA to the Validation Set (The Sobel has been applied before and it's not different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "181d24a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1770, 2048), (1770, 32))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_resampled_pca = pca_resampled.transform(X_val_conc_sobeled_flattened)\n",
    "X_val_conc_sobeled_flattened.shape , X_val_resampled_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4e0986",
   "metadata": {},
   "source": [
    "### Apply MLP on no resample feature engineered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5b45016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train_reduced_conc_sobeled_flattened_pca_shuffled, y_train_reduced_conc_shuffled= shuffle(X_train_reduced_conc_sobeled_flattened_pca, y_train_reduced_conc, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c472832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999859943977591 0.8903954802259887\n"
     ]
    }
   ],
   "source": [
    "clf_ = MLPClassifier(random_state = 4, max_iter=500).fit(X_train_reduced_conc_sobeled_flattened_pca_shuffled, y_train_reduced_conc_shuffled)\n",
    "\n",
    "print(clf_.score(X_train_reduced_conc_sobeled_flattened_pca_shuffled, y_train_reduced_conc_shuffled) ,\n",
    "      clf_.score(X_val_conc_sobeled_flattened_pca, y_val_conc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "226c4c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      1500\n",
      "           1       0.61      0.79      0.69       270\n",
      "\n",
      "    accuracy                           0.89      1770\n",
      "   macro avg       0.78      0.85      0.81      1770\n",
      "weighted avg       0.91      0.89      0.90      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_.predict(X_val_conc_sobeled_flattened_pca)\n",
    "print(classification_report(y_val_conc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ef1c3",
   "metadata": {},
   "source": [
    "#### Much much better accuracy !! \n",
    "#### Now let's try this on the resampled feature engineered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c504a4c",
   "metadata": {},
   "source": [
    "### Apply MLP on Resample feature engineered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e0f2f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conc_sobeled_resampled_pca_shuffled, y_resampled_shuffled= shuffle(X_train_conc_sobeled_resampled_pca, y_resampled, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eca34854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956140350877193 0.22090395480225988\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state = 4, max_iter=500).fit(X_train_conc_sobeled_resampled_pca_shuffled, y_resampled_shuffled)\n",
    "\n",
    "print(clf.score(X_train_conc_sobeled_resampled_pca_shuffled, y_resampled_shuffled) ,\n",
    "      clf.score(X_val_resampled_pca, y_val_conc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d06c5af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.09      0.17      1500\n",
      "           1       0.16      0.94      0.27       270\n",
      "\n",
      "    accuracy                           0.22      1770\n",
      "   macro avg       0.52      0.51      0.22      1770\n",
      "weighted avg       0.78      0.22      0.18      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val_resampled_pca)\n",
    "print(classification_report(y_val_conc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de59cef3",
   "metadata": {},
   "source": [
    "#### Again, undersampling resulting in very bad results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7004fe04",
   "metadata": {},
   "source": [
    "## 1.7 Discussion on Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11345b",
   "metadata": {},
   "source": [
    "### First prepare the test data to suit our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2368d44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 32, 32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "15e9722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_conc = []\n",
    "y_test_conc = []\n",
    "i, j, k = 0, 0, 0\n",
    "for i in range(X_test.shape[0]):\n",
    "    for j in range(i+1, X_test.shape[0]):\n",
    "        X_test_conc.append(np.dstack([X_test[i], X_test[j]]))\n",
    "        if y_test[i] == y_test [j]:\n",
    "            y_test_conc.append(1)\n",
    "        else:\n",
    "            y_test_conc.append(0)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f3e2534d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1770, 32, 32, 2), (1770,))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_conc = np.array(X_test_conc)\n",
    "y_test_conc = np.array(y_test_conc)\n",
    "X_test_conc.shape , y_test_conc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3e5eb5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1770, 32, 32, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_conc_sobeled = []\n",
    "for image in X_test_conc:\n",
    "    # sharpened = unsharp_mask(image, radius=20, amount=1)\n",
    "    sobeled = sobel(image)\n",
    "    X_test_conc_sobeled.append(sobeled)\n",
    "X_test_conc_sobeled = np.array(X_test_conc_sobeled)\n",
    "X_test_conc_sobeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "66a0986d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1770, 2048)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_conc_sobeled_flattened = X_test_conc_sobeled.reshape(X_test_conc_sobeled.shape[0], -1)\n",
    "X_test_conc_sobeled_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "63e5cddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1770, 32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_conc_sobeled_flattened_pca = pca.transform(X_test_conc_sobeled_flattened)\n",
    "X_test_conc_sobeled_flattened_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c892d09",
   "metadata": {},
   "source": [
    "### Test noResample_FeatureEngineered Classifier (our best one so far) on TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d90bfff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94      1500\n",
      "           1       0.62      0.79      0.70       270\n",
      "\n",
      "    accuracy                           0.89      1770\n",
      "   macro avg       0.79      0.85      0.82      1770\n",
      "weighted avg       0.91      0.89      0.90      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_.predict(X_test_conc_sobeled_flattened_pca)\n",
    "print(classification_report(y_test_conc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e220a",
   "metadata": {},
   "source": [
    "### Test our first base classifier (before feature engineering) on TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "be106040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.61      0.71      1500\n",
      "           1       0.15      0.37      0.21       270\n",
      "\n",
      "    accuracy                           0.57      1770\n",
      "   macro avg       0.49      0.49      0.46      1770\n",
      "weighted avg       0.74      0.57      0.63      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_base.predict(X_test_conc.reshape(X_test_conc.shape[0],-1))\n",
    "print(classification_report(y_test_conc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eac6c3",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "- By the looking at the last two classifier experiments, we can see the great improvement that the feature engineering (the Sobel filter only) and the feature extraction by dimensionality reduction (PCA) have done to the model.\n",
    "- The improvement is not just in the overall accuracy, it's also in the precision, recall scores which reflects the model's performance on rare cases and its generelization ability.\n",
    "- Regarding my choice of the filter. Since our data is texture images, I figured that the edges would be a good representation of each image. Given that the images' colors and all the other details are of no importance, only the edges and their relationship to eachother matters. Because that's what defines a texture.\n",
    "- Regarding the PCA choice, it's the most famous and most efficient dimensionality reduction method I know, and given that we have had so many features that we wanted to get rid of, it seemed like a reasonable approach and so it was.\n",
    "- A side note on the accuracy metrics of our champion model: The reason why class0 scores are higher than class1 is because class0 exists more in the train set. a solution to this could be to oversample the rarest class instead of undersample because as we saw, undersampling did not do very well, the model needed more data to be able to capture the details (it underfitted). Another solution could be to make the model more complex as well.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
